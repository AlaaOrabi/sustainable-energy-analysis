# -*- coding: utf-8 -*-
"""CO2_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EejAEY7JTSTwfd8fXGIf4Rhpn7RGtBcF
"""

# -*- coding: utf-8 -*-
"""Enhanced Exploratory Data Analysis with Machine Learning"""

# Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from plotly.subplots import make_subplots
import warnings
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Configurations
warnings.filterwarnings('ignore')
pd.options.display.float_format = '{:.2f}'.format

# Load the dataset
data = pd.read_csv('global-data-on-sustainable-energy.csv')

# Overview of the dataset
print("Dataset Summary:")
display(data.describe().transpose())

# Basic EDA with Visualizations (as in the original code)

# Prepare dataset for ML - Predicting CO₂ Emissions based on energy indicators
# Select relevant features and drop rows with missing target (CO₂ emissions)
features = [
    'Renewable energy share in the total final energy consumption (%)',
    'Electricity from fossil fuels (TWh)', 'Electricity from nuclear (TWh)',
    'Electricity from renewables (TWh)', 'Low-carbon electricity (% electricity)',
    'Primary energy consumption per capita (kWh/person)'
]
target = 'Value_co2_emissions_kt_by_country'
ml_data = data[features + [target]].dropna()

# Splitting data into features (X) and target (y)
X = ml_data[features]
y = ml_data[target]

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Pipeline for data preprocessing and model comparison
numeric_features = X.select_dtypes(include=['float64', 'int']).columns
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Define models
models = {
    'Linear Regression': LinearRegression(),
    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)
}

# Evaluate models
results = []
for model_name, model in models.items():
    # Pipeline with preprocessing and model
    pipeline = Pipeline(steps=[
        ('preprocessor', ColumnTransformer(
            transformers=[('num', numeric_transformer, numeric_features)]
        )),
        ('model', model)
    ])

    # Train the model
    pipeline.fit(X_train, y_train)

    # Predict and evaluate
    y_pred = pipeline.predict(X_test)
    rmse = mean_squared_error(y_test, y_pred, squared=False)
    r2 = r2_score(y_test, y_pred)

    results.append({
        'Model': model_name,
        'RMSE': rmse,
        'R2 Score': r2
    })

# Display results
results_df = pd.DataFrame(results).sort_values(by='RMSE')
print("Model Performance Comparison:")
display(results_df)

# Plotting the actual vs predicted values for the best model
best_model_name = results_df.iloc[0]['Model']
best_model = models[best_model_name]
pipeline = Pipeline(steps=[
    ('preprocessor', ColumnTransformer(
        transformers=[('num', numeric_transformer, numeric_features)]
    )),
    ('model', best_model)
])

# Retrain the best model on all data and plot results
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel("Actual CO₂ Emissions (kt)")
plt.ylabel("Predicted CO₂ Emissions (kt)")
plt.title(f"Actual vs Predicted CO₂ Emissions - {best_model_name}")
plt.plot([y.min(), y.max()], [y.min(), y.max()], '--r', lw=2)
plt.show()

# Display feature importance if the model has this attribute
if hasattr(best_model, 'feature_importances_'):
    feature_importances = best_model.feature_importances_
    feature_importances_df = pd.DataFrame({
        'Feature': numeric_features,
        'Importance': feature_importances
    }).sort_values(by='Importance', ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=feature_importances_df, palette='viridis')
    plt.title(f"Feature Importances - {best_model_name}")
    plt.show()